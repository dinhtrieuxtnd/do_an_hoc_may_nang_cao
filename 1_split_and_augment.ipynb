{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cacab47f",
   "metadata": {},
   "source": [
    "# 1. Chia Train/Test và Augment Dữ Liệu (Back Translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14d1cdc",
   "metadata": {},
   "source": [
    "## 1.1. Import Thư Viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190228ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã import thành công các thư viện!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from googletrans import Translator\n",
    "import time\n",
    "import torch\n",
    "\n",
    "# Set seed\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "\n",
    "print('Đã import thành công các thư viện!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f96887",
   "metadata": {},
   "source": [
    "## 1.2. Cấu Hình Tham Số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2931307f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ./data/dataset.csv\n",
      "Output directory: ./split_augmented_data/\n",
      " Test size: 0.2 (train size: 0.8)\n",
      " Augment ratio (train only): 0.5\n",
      " Back Translation - Languages: ['de', 'fr'], Max length: 500\n",
      " Delay between requests: 0.5s\n",
      "\n",
      " CHỈ sử dụng Back Translation để augment dữ liệu!\n"
     ]
    }
   ],
   "source": [
    "# Đường dẫn\n",
    "DATA_PATH = './data/dataset.csv'\n",
    "OUTPUT_DIR = './split_augmented_data'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Tham số chia dữ liệu\n",
    "TEST_SIZE = 0.2  # 20% cho test, 80% cho train\n",
    "\n",
    "# Tham số augmentation (CHỈ ÁP DỤNG CHO TRAIN)\n",
    "AUGMENT_RATIO = 0.5  # Tăng 50% dữ liệu train\n",
    "\n",
    "# Back translation params\n",
    "INTERMEDIATE_LANGS = ['de', 'fr']  # Dùng nhiều ngôn ngữ để đa dạng hơn\n",
    "BACKTRANS_DELAY = 0.5  # Delay giữa các request để tránh rate limit\n",
    "MAX_BACKTRANS_LENGTH = 500  # Độ dài tối đa của text để back translate\n",
    "\n",
    "print(f'Input: {DATA_PATH}')\n",
    "print(f'Output directory: {OUTPUT_DIR}/')\n",
    "print(f' Test size: {TEST_SIZE} (train size: {1-TEST_SIZE})')\n",
    "print(f' Augment ratio (train only): {AUGMENT_RATIO}')\n",
    "print(f' Back Translation - Languages: {INTERMEDIATE_LANGS}, Max length: {MAX_BACKTRANS_LENGTH}')\n",
    "print(f' Delay between requests: {BACKTRANS_DELAY}s')\n",
    "print(f'\\nCHỈ sử dụng Back Translation để augment dữ liệu!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dc249b",
   "metadata": {},
   "source": [
    "## 1.3. Load và Chia Dữ Liệu Gốc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81e3be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang load dữ liệu gốc...\n",
      "\n",
      "Đã load 50,000 samples\n",
      "\n",
      "Phân phối nhãn gốc:\n",
      "sentiment\n",
      "negative    25000\n",
      "positive    25000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Đang chia dữ liệu train/test (80%/20%)...\n",
      "\n",
      "Đã chia dữ liệu:\n",
      "   Train: 40,000 samples\n",
      "   Test: 10,000 samples\n",
      "\n",
      "Phân phối nhãn train:\n",
      "sentiment\n",
      "negative    20000\n",
      "positive    20000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Phân phối nhãn test:\n",
      "sentiment\n",
      "negative    5000\n",
      "positive    5000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Đã load 50,000 samples\n",
      "\n",
      "Phân phối nhãn gốc:\n",
      "sentiment\n",
      "negative    25000\n",
      "positive    25000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Đang chia dữ liệu train/test (80%/20%)...\n",
      "\n",
      "Đã chia dữ liệu:\n",
      "   Train: 40,000 samples\n",
      "   Test: 10,000 samples\n",
      "\n",
      "Phân phối nhãn train:\n",
      "sentiment\n",
      "negative    20000\n",
      "positive    20000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Phân phối nhãn test:\n",
      "sentiment\n",
      "negative    5000\n",
      "positive    5000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Đang load dữ liệu gốc...')\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f'\\nĐã load {len(df):,} samples')\n",
    "print(f'\\nPhân phối nhãn gốc:')\n",
    "print(df['sentiment'].value_counts().sort_index())\n",
    "\n",
    "# Chia train/test - QUAN TRỌNG: Stratify để giữ cân bằng nhãn\n",
    "print(f'\\nĐang chia dữ liệu train/test ({100*(1-TEST_SIZE):.0f}%/{100*TEST_SIZE:.0f}%)...')\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=SEED,\n",
    "    stratify=df['sentiment']  # Giữ cân bằng nhãn\n",
    ")\n",
    "\n",
    "print(f'\\nĐã chia dữ liệu:')\n",
    "print(f'   Train: {len(train_df):,} samples')\n",
    "print(f'   Test: {len(test_df):,} samples')\n",
    "\n",
    "print(f'\\nPhân phối nhãn train:')\n",
    "print(train_df['sentiment'].value_counts().sort_index())\n",
    "\n",
    "print(f'\\nPhân phối nhãn test:')\n",
    "print(test_df['sentiment'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af5e3c3",
   "metadata": {},
   "source": [
    "## 1.4. Lưu Test Set (KHÔNG AUGMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b38b146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu test set (KHÔNG augment): ./split_augmented_data\\test_original.csv\n",
      "   Số samples: 10,000\n",
      "   Test set này sẽ KHÔNG bao giờ được augment!\n"
     ]
    }
   ],
   "source": [
    "# Lưu test set nguyên bản - KHÔNG ĐƯỢC AUGMENT\n",
    "test_path = os.path.join(OUTPUT_DIR, 'test_original.csv')\n",
    "test_df.to_csv(test_path, index=False)\n",
    "\n",
    "print(f'Đã lưu test set (KHÔNG augment): {test_path}')\n",
    "print(f'   Số samples: {len(test_df):,}')\n",
    "print(f'   Test set này sẽ KHÔNG bao giờ được augment!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fd7cad",
   "metadata": {},
   "source": [
    "## 1.5. Định Nghĩa Back Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a8ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã định nghĩa BackTranslator class\n"
     ]
    }
   ],
   "source": [
    "class BackTranslator:\n",
    "    \"\"\"\n",
    "    Back translation: English → Intermediate Language → English\n",
    "    Tạo phiên bản paraphrase giữ nguyên ý nghĩa\n",
    "    CHỈ SỬ DỤNG CHO TẬP TRAIN!\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, intermediate_langs=['de', 'fr', 'es']):\n",
    "        self.translator = Translator()\n",
    "        self.intermediate_langs = intermediate_langs\n",
    "        print(f'BackTranslator initialized')\n",
    "        print(f'   Intermediate languages: {intermediate_langs}')\n",
    "    \n",
    "    def back_translate(self, text, intermediate_lang=None, max_retries=3):\n",
    "        \"\"\"\n",
    "        Back translate text: en → intermediate_lang → en\n",
    "        \n",
    "        Args:\n",
    "            text: Text gốc (English)\n",
    "            intermediate_lang: Ngôn ngữ trung gian (nếu None thì chọn random)\n",
    "            max_retries: Số lần retry nếu lỗi\n",
    "        \n",
    "        Returns:\n",
    "            Back-translated text hoặc text gốc nếu lỗi\n",
    "        \"\"\"\n",
    "        if not text or len(text.strip()) == 0:\n",
    "            return text\n",
    "        \n",
    "        # Chọn ngôn ngữ trung gian\n",
    "        if intermediate_lang is None:\n",
    "            intermediate_lang = random.choice(self.intermediate_langs)\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                # Step 1: English → Intermediate Language\n",
    "                translated = self.translator.translate(\n",
    "                    text, \n",
    "                    src='en', \n",
    "                    dest=intermediate_lang\n",
    "                )\n",
    "                intermediate_text = translated.text\n",
    "                \n",
    "                # Small delay\n",
    "                time.sleep(0.2)\n",
    "                \n",
    "                # Step 2: Intermediate Language → English\n",
    "                back_translated = self.translator.translate(\n",
    "                    intermediate_text,\n",
    "                    src=intermediate_lang,\n",
    "                    dest='en'\n",
    "                )\n",
    "                result = back_translated.text\n",
    "                \n",
    "                return result\n",
    "                \n",
    "            except Exception as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    # Wait longer before retry\n",
    "                    time.sleep(2 ** attempt)\n",
    "                    continue\n",
    "                else:\n",
    "                    # Return original text if all retries fail\n",
    "                    return text\n",
    "        \n",
    "        return text\n",
    "\n",
    "print('Đã định nghĩa BackTranslator class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c75d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BackTranslator initialized\n",
      "   Intermediate languages: ['de', 'fr']\n",
      "Sẵn sàng để augment TRAIN SET với Back Translation!\n"
     ]
    }
   ],
   "source": [
    "back_translator = BackTranslator(intermediate_langs=INTERMEDIATE_LANGS)\n",
    "print('Sẵn sàng để augment TRAIN SET với Back Translation!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5f8658",
   "metadata": {},
   "source": [
    "## 1.7. Test Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7fefa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing augmentation với mẫu từ TRAIN set...\n",
      "\n",
      "================================================================================\n",
      "Sentiment: negative\n",
      "\n",
      "Original:\n",
      "   Why, oh why, is this trash considered a classic? I've seen higher body counts on episodes of The Simpsons. Virtually nothing happens in this film and ...\n",
      "\n",
      "Back-translated:\n",
      "   Why, oh why, is this garbage considered a classic? I've seen a higher body count in The Simpsons episodes. Virtually nothing happens in this movie and...\n",
      "\n",
      "================================================================================\n",
      "Sentiment: negative\n",
      "\n",
      "Original:\n",
      "   Why, oh why, is this trash considered a classic? I've seen higher body counts on episodes of The Simpsons. Virtually nothing happens in this film and ...\n",
      "\n",
      "Back-translated:\n",
      "   Why, oh why, is this garbage considered a classic? I've seen a higher body count in The Simpsons episodes. Virtually nothing happens in this movie and...\n",
      "\n",
      "================================================================================\n",
      "Sentiment: negative\n",
      "\n",
      "Original:\n",
      "   First off, Mexican Werewolf in Texas' title is misleading as many others have pointed out. It is actually about El Chupacabra, which is a similar crea...\n",
      "\n",
      "Back-translated:\n",
      "   First of all, the title of \"Mexican Werewolf in Texas\" is misleading, as many others have already pointed out. It's actually about El Chupacabra, a cr...\n",
      "\n",
      "================================================================================\n",
      "Sentiment: negative\n",
      "\n",
      "Original:\n",
      "   First off, Mexican Werewolf in Texas' title is misleading as many others have pointed out. It is actually about El Chupacabra, which is a similar crea...\n",
      "\n",
      "Back-translated:\n",
      "   First of all, the title of \"Mexican Werewolf in Texas\" is misleading, as many others have already pointed out. It's actually about El Chupacabra, a cr...\n",
      "\n",
      "================================================================================\n",
      "Sentiment: positive\n",
      "\n",
      "Original:\n",
      "   I rate this 10 out of 10. Why?<br /><br />* It offers insight into something I barely understand - the surfers surf because it's all they want to do; ...\n",
      "\n",
      "Back-translated:\n",
      "   I rate this 10 out of 10. Why?<br /><br />* This gives insight into something I barely understand: Surfers surf because that's all they want to do; No...\n",
      "\n",
      "================================================================================\n",
      "Sentiment: positive\n",
      "\n",
      "Original:\n",
      "   I rate this 10 out of 10. Why?<br /><br />* It offers insight into something I barely understand - the surfers surf because it's all they want to do; ...\n",
      "\n",
      "Back-translated:\n",
      "   I rate this 10 out of 10. Why?<br /><br />* This gives insight into something I barely understand: Surfers surf because that's all they want to do; No...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test với 3 samples từ TRAIN set\n",
    "print('Testing augmentation với mẫu từ TRAIN set...\\n')\n",
    "test_samples = train_df.sample(3, random_state=42)\n",
    "\n",
    "for idx, row in test_samples.iterrows():\n",
    "    original = row['review']\n",
    "    \n",
    "    # Test back translation\n",
    "    truncated = original[:MAX_BACKTRANS_LENGTH] if len(original) > MAX_BACKTRANS_LENGTH else original\n",
    "    bt_augmented = back_translator.back_translate(truncated)\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Sentiment: {row['sentiment']}\")\n",
    "    print(f\"\\nOriginal:\")\n",
    "    print(f\"   {original[:150]}...\" if len(original) > 150 else f\"   {original}\")\n",
    "    print(f\"\\nBack-translated:\")\n",
    "    print(f\"   {bt_augmented[:150]}...\" if len(bt_augmented) > 150 else f\"   {bt_augmented}\")\n",
    "    print()\n",
    "    \n",
    "    time.sleep(BACKTRANS_DELAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb20a2",
   "metadata": {},
   "source": [
    "## 1.8. Augment CHỈ Tập TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57d0fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CHUẨN BỊ AUGMENT TẬP TRAIN (BACK TRANSLATION)\n",
      "================================================================================\n",
      "\n",
      "Số samples cần augment cho TRAIN set:\n",
      "   Sentiment negative: 10,000 samples\n",
      "   Sentiment positive: 10,000 samples\n",
      "\n",
      " Thời gian ước tính:\n",
      "   Back Translation: ~1500.0 phút (20,000 samples)\n",
      "\n",
      " Thời gian ước tính CHO MỖI SENTIMENT:\n",
      "   Sentiment negative: ~750.0 phút\n",
      "   Sentiment positive: ~750.0 phút\n",
      "\n",
      "Mỗi sentiment có thể chạy riêng trong các cell khác nhau!\n",
      "\n",
      "Đã khởi tạo augmented_train_data = []\n"
     ]
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('CHUẨN BỊ AUGMENT TẬP TRAIN (BACK TRANSLATION)')\n",
    "print('='*80)\n",
    "\n",
    "# Tính số samples cần augment cho mỗi class trong TRAIN set\n",
    "train_samples_per_class = train_df['sentiment'].value_counts().to_dict()\n",
    "augment_per_class = {label: int(count * AUGMENT_RATIO) \n",
    "                     for label, count in train_samples_per_class.items()}\n",
    "\n",
    "print(f'\\nSố samples cần augment cho TRAIN set:')\n",
    "total_augment = sum(augment_per_class.values())\n",
    "for label in sorted(train_df['sentiment'].unique()):\n",
    "    print(f'   Sentiment {label}: {augment_per_class[label]:,} samples')\n",
    "\n",
    "# Ước tính thời gian (back translation)\n",
    "bt_time_est = total_augment * (4 + BACKTRANS_DELAY)  # ~4s per sample + delay\n",
    "total_time_est = bt_time_est / 60\n",
    "\n",
    "print(f'\\n Thời gian ước tính:')\n",
    "print(f'   Back Translation: ~{total_time_est:.1f} phút ({total_augment:,} samples)')\n",
    "\n",
    "# Ước tính thời gian cho MỖI SENTIMENT\n",
    "print(f'\\n Thời gian ước tính CHO MỖI SENTIMENT:')\n",
    "for label in sorted(train_df['sentiment'].unique()):\n",
    "    bt_time = augment_per_class[label] * (4 + BACKTRANS_DELAY) / 60\n",
    "    print(f'   Sentiment {label}: ~{bt_time:.1f} phút')\n",
    "\n",
    "print(f'\\nMỗi sentiment có thể chạy riêng trong các cell khác nhau!')\n",
    "\n",
    "# Khởi tạo list để lưu augmented data\n",
    "# QUAN TRỌNG: Chạy cell này TRƯỚC KHI chạy các cell augment bên dưới!\n",
    "augmented_train_data = []\n",
    "print(f'\\nĐã khởi tạo augmented_train_data = []')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b72443",
   "metadata": {},
   "source": [
    "## 1.8.1. Augment Sentiment \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177f9ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Đang augment TRAIN sentiment negative\n",
      "================================================================================\n",
      "\n",
      "Back Translation (10,000 samples)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2339dd995644e11943463e48aced5a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BackTrans negative:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hoàn thành BackTrans: 9997/10000 thành công trong 580.2 phút\n",
      "\n",
      "Đã augment xong sentiment negative!\n",
      "   Total augmented: 9,997 samples\n"
     ]
    }
   ],
   "source": [
    "sentiment_label = \"negative\"\n",
    "\n",
    "print(f'\\n{\"=\"*80}')\n",
    "print(f'Đang augment TRAIN sentiment {sentiment_label}')\n",
    "print(f'{\"=\"*80}')\n",
    "\n",
    "# Lấy tất cả samples của class này từ TRAIN\n",
    "class_samples = train_df[train_df['sentiment'] == sentiment_label]\n",
    "\n",
    "# ===== BACK TRANSLATION AUGMENTATION =====\n",
    "num_augment = augment_per_class[sentiment_label]\n",
    "print(f'\\nBack Translation ({num_augment:,} samples)...')\n",
    "\n",
    "if num_augment > 0:\n",
    "    bt_samples = class_samples.sample(n=num_augment, replace=True, random_state=SEED)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    success_count = 0\n",
    "    \n",
    "    for idx, row in tqdm(bt_samples.iterrows(), total=num_augment, desc=f'BackTrans {sentiment_label}'):\n",
    "        original = row['review']\n",
    "        # Truncate để tránh quá dài\n",
    "        truncated = original[:MAX_BACKTRANS_LENGTH] if len(original) > MAX_BACKTRANS_LENGTH else original\n",
    "        \n",
    "        back_translated = back_translator.back_translate(truncated)\n",
    "        if back_translated and back_translated != truncated:\n",
    "            augmented_train_data.append({\n",
    "                'review': back_translated,\n",
    "                'sentiment': sentiment_label,\n",
    "                'augment_method': 'BackTranslation'\n",
    "            })\n",
    "            success_count += 1\n",
    "        \n",
    "        time.sleep(BACKTRANS_DELAY)\n",
    "    \n",
    "    bt_elapsed = time.time() - start_time\n",
    "    print(f'   Hoàn thành BackTrans: {success_count}/{num_augment} thành công trong {bt_elapsed/60:.1f} phút')\n",
    "else:\n",
    "    print(f'   Bỏ qua BackTranslation (num_augment = 0)')\n",
    "\n",
    "print(f'\\nĐã augment xong sentiment {sentiment_label}!')\n",
    "print(f'   Total augmented: {success_count:,} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5700ae6e",
   "metadata": {},
   "source": [
    "## 1.8.2. Augment Sentiment \"positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1c422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Đang augment TRAIN sentiment positive\n",
      "================================================================================\n",
      "\n",
      "Back Translation (10,000 samples)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813e8a3ca75f4c26bfb727d6fb7a528a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BackTrans positive:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hoàn thành BackTrans: 9998/10000 thành công trong 579.4 phút\n",
      "\n",
      "Đã augment xong sentiment positive!\n",
      "   Total augmented: 9,998 samples\n"
     ]
    }
   ],
   "source": [
    "sentiment_label = \"positive\"\n",
    "\n",
    "print(f'\\n{\"=\"*80}')\n",
    "print(f'Đang augment TRAIN sentiment {sentiment_label}')\n",
    "print(f'{\"=\"*80}')\n",
    "\n",
    "# Lấy tất cả samples của class này từ TRAIN\n",
    "class_samples = train_df[train_df['sentiment'] == sentiment_label]\n",
    "\n",
    "# ===== BACK TRANSLATION AUGMENTATION =====\n",
    "num_augment = augment_per_class[sentiment_label]\n",
    "print(f'\\nBack Translation ({num_augment:,} samples)...')\n",
    "\n",
    "if num_augment > 0:\n",
    "    bt_samples = class_samples.sample(n=num_augment, replace=True, random_state=SEED)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    success_count = 0\n",
    "    \n",
    "    for idx, row in tqdm(bt_samples.iterrows(), total=num_augment, desc=f'BackTrans {sentiment_label}'):\n",
    "        original = row['review']\n",
    "        # Truncate để tránh quá dài\n",
    "        truncated = original[:MAX_BACKTRANS_LENGTH] if len(original) > MAX_BACKTRANS_LENGTH else original\n",
    "        \n",
    "        back_translated = back_translator.back_translate(truncated)\n",
    "        if back_translated and back_translated != truncated:\n",
    "            augmented_train_data.append({\n",
    "                'review': back_translated,\n",
    "                'sentiment': sentiment_label,\n",
    "                'augment_method': 'BackTranslation'\n",
    "            })\n",
    "            success_count += 1\n",
    "        \n",
    "        time.sleep(BACKTRANS_DELAY)\n",
    "    \n",
    "    bt_elapsed = time.time() - start_time\n",
    "    print(f'   Hoàn thành BackTrans: {success_count}/{num_augment} thành công trong {bt_elapsed/60:.1f} phút')\n",
    "else:\n",
    "    print(f'   Bỏ qua BackTranslation (num_augment = 0)')\n",
    "\n",
    "print(f'\\nĐã augment xong sentiment {sentiment_label}!')\n",
    "print(f'   Total augmented: {success_count:,} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb75f0",
   "metadata": {},
   "source": [
    "## 1.8.3. Tổng Kết Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04dca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ĐÃ HOÀN THÀNH TẤT CẢ AUGMENTATION!\n",
      "================================================================================\n",
      "\n",
      "Tổng kết:\n",
      "   Tổng augmented samples: 19,995\n",
      "\n",
      "Phân bố theo phương pháp:\n",
      "   BackTranslation: 19,995 (100.0%)\n",
      "\n",
      "Phân bố theo sentiment:\n",
      "   negative: 9,997 (50.0%)\n",
      "   positive: 9,998 (50.0%)\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n{\"=\"*80}')\n",
    "print(f'ĐÃ HOÀN THÀNH TẤT CẢ AUGMENTATION!')\n",
    "print(f'{\"=\"*80}')\n",
    "\n",
    "print(f'\\nTổng kết:')\n",
    "print(f'   Tổng augmented samples: {len(augmented_train_data):,}')\n",
    "\n",
    "# Thống kê theo method\n",
    "if len(augmented_train_data) > 0:\n",
    "    df_aug_temp = pd.DataFrame(augmented_train_data)\n",
    "    \n",
    "    print(f'\\nPhân bố theo phương pháp:')\n",
    "    for method, count in df_aug_temp['augment_method'].value_counts().items():\n",
    "        pct = count / len(df_aug_temp) * 100\n",
    "        print(f'   {method}: {count:,} ({pct:.1f}%)')\n",
    "    \n",
    "    print(f'\\nPhân bố theo sentiment:')\n",
    "    for sentiment, count in df_aug_temp['sentiment'].value_counts().sort_index().items():\n",
    "        pct = count / len(df_aug_temp) * 100\n",
    "        print(f'   {sentiment}: {count:,} ({pct:.1f}%)')\n",
    "else:\n",
    "    print(f'\\nChưa có dữ liệu augmented! Hãy chạy các cell 1.8.1 và 1.8.2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a9eca1",
   "metadata": {},
   "source": [
    "## 1.9. Kết Hợp Train Gốc và Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f660c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "THỐNG KÊ DỮ LIỆU SAU KHI AUGMENT\n",
      "================================================================================\n",
      "\n",
      "TRAIN SET (ĐÃ AUGMENT - BACK TRANSLATION):\n",
      "   Original train: 40,000 samples\n",
      "   Augmented (Back Translation): 19,995 samples\n",
      "   Total train: 59,995 samples\n",
      "\n",
      "   Phân phối nhãn train (sau augment):\n",
      "      Sentiment negative: 29,997 (50.0%)\n",
      "      Sentiment positive: 29,998 (50.0%)\n",
      "\n",
      "TEST SET (KHÔNG AUGMENT - NGUYÊN BẢN):\n",
      "   Total test: 10,000 samples\n",
      "\n",
      "   Phân phối nhãn test (nguyên bản):\n",
      "      Sentiment negative: 5,000 (50.0%)\n",
      "      Sentiment positive: 5,000 (50.0%)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Tạo DataFrame augmented train (bỏ cột augment_method trước khi kết hợp)\n",
    "df_augmented_train = pd.DataFrame(augmented_train_data)\n",
    "df_augmented_train = df_augmented_train[['review', 'sentiment']]  # Chỉ giữ 2 cột cần thiết\n",
    "\n",
    "# Kết hợp train gốc với augmented train\n",
    "train_combined = pd.concat([train_df, df_augmented_train], ignore_index=True)\n",
    "\n",
    "# Shuffle\n",
    "train_combined = train_combined.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "print('='*80)\n",
    "print('THỐNG KÊ DỮ LIỆU SAU KHI AUGMENT')\n",
    "print('='*80)\n",
    "\n",
    "print(f'\\nTRAIN SET (ĐÃ AUGMENT - BACK TRANSLATION):')\n",
    "print(f'   Original train: {len(train_df):,} samples')\n",
    "print(f'   Augmented (Back Translation): {len(df_augmented_train):,} samples')\n",
    "print(f'   Total train: {len(train_combined):,} samples')\n",
    "print(f'\\n   Phân phối nhãn train (sau augment):')\n",
    "for label, count in train_combined['sentiment'].value_counts().sort_index().items():\n",
    "    pct = count / len(train_combined) * 100\n",
    "    print(f'      Sentiment {label}: {count:,} ({pct:.1f}%)')\n",
    "\n",
    "print(f'\\nTEST SET (KHÔNG AUGMENT - NGUYÊN BẢN):')\n",
    "print(f'   Total test: {len(test_df):,} samples')\n",
    "print(f'\\n   Phân phối nhãn test (nguyên bản):')\n",
    "for label, count in test_df['sentiment'].value_counts().sort_index().items():\n",
    "    pct = count / len(test_df) * 100\n",
    "    print(f'      Sentiment {label}: {count:,} ({pct:.1f}%)')\n",
    "\n",
    "print('\\n' + '='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ece380b",
   "metadata": {},
   "source": [
    "## 1.10. Lưu Dữ Liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37bbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang lưu dữ liệu...\n",
      "\n",
      "Đã lưu TRAIN (augmented): ./split_augmented_data\\train_augmented.csv\n",
      "   Samples: 59,995\n",
      "   Size: 59.66 MB\n",
      "\n",
      "TEST (original - đã lưu trước đó): ./split_augmented_data\\test_original.csv\n",
      "   Samples: 10,000\n",
      "   Size: 12.60 MB\n",
      "Đã lưu TRAIN (augmented): ./split_augmented_data\\train_augmented.csv\n",
      "   Samples: 59,995\n",
      "   Size: 59.66 MB\n",
      "\n",
      "TEST (original - đã lưu trước đó): ./split_augmented_data\\test_original.csv\n",
      "   Samples: 10,000\n",
      "   Size: 12.60 MB\n"
     ]
    }
   ],
   "source": [
    "print('Đang lưu dữ liệu...\\n')\n",
    "\n",
    "# Lưu train augmented\n",
    "train_path = os.path.join(OUTPUT_DIR, 'train_augmented.csv')\n",
    "train_combined.to_csv(train_path, index=False)\n",
    "print(f'Đã lưu TRAIN (augmented): {train_path}')\n",
    "print(f'   Samples: {len(train_combined):,}')\n",
    "print(f'   Size: {os.path.getsize(train_path) / 1024 / 1024:.2f} MB')\n",
    "\n",
    "# Test đã được lưu ở bước 1.4\n",
    "print(f'\\nTEST (original - đã lưu trước đó): {test_path}')\n",
    "print(f'   Samples: {len(test_df):,}')\n",
    "print(f'   Size: {os.path.getsize(test_path) / 1024 / 1024:.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2d787a",
   "metadata": {},
   "source": [
    "## 1.11. Tổng Kết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16508315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "HOÀN THÀNH CHIA VÀ AUGMENT DỮ LIỆU!\n",
      "================================================================================\n",
      "\n",
      "Tổng Kết:\n",
      "   Input: ./data/dataset.csv\n",
      "   Original dataset: 50,000 samples\n",
      "   Train/Test split: 80%/20%\n",
      "   Files đã tạo:\n",
      "      1. ./split_augmented_data\\train_augmented.csv\n",
      "         - Train gốc: 40,000 samples\n",
      "         - Augmented (Back Translation): 19,995 samples\n",
      "         - Tổng: 59,995 samples\n",
      "\n",
      "      2. ./split_augmented_data\\test_original.csv\n",
      "         - Test gốc (KHÔNG augment): 10,000 samples\n",
      "\n",
      " LƯU Ý QUAN TRỌNG:\n",
      "   Tập TRAIN đã được augment bằng Back Translation:\n",
      "      • Back Translation: Paraphrase qua ngôn ngữ trung gian\n",
      "   Tập TEST giữ NGUYÊN - KHÔNG augment\n",
      "   Tránh data leakage - đánh giá khách quan!\n",
      "\n",
      "Bước tiếp theo:\n",
      "   1. Chạy notebook 2_encode_split_data.ipynb để mã hóa dữ liệu\n",
      "   2. Chạy notebook 3_train_with_split.ipynb để train model\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Đã giải phóng bộ nhớ\n"
     ]
    }
   ],
   "source": [
    "print('\\n' + '='*80)\n",
    "print('HOÀN THÀNH CHIA VÀ AUGMENT DỮ LIỆU!')\n",
    "print('='*80)\n",
    "\n",
    "print(f'\\nTổng Kết:')\n",
    "print(f'   Input: {DATA_PATH}')\n",
    "print(f'   Original dataset: {len(df):,} samples')\n",
    "print(f'   Train/Test split: {100*(1-TEST_SIZE):.0f}%/{100*TEST_SIZE:.0f}%')\n",
    "print(f'   Files đã tạo:')\n",
    "print(f'      1. {train_path}')\n",
    "print(f'         - Train gốc: {len(train_df):,} samples')\n",
    "print(f'         - Augmented (Back Translation): {len(df_augmented_train):,} samples')\n",
    "print(f'         - Tổng: {len(train_combined):,} samples')\n",
    "print(f'\\n      2. {test_path}')\n",
    "print(f'         - Test gốc (KHÔNG augment): {len(test_df):,} samples')\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "\n",
    "# Giải phóng bộ nhớ\n",
    "del back_translator\n",
    "print('\\nĐã giải phóng bộ nhớ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97715ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
